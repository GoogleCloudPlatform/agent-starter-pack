{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ§ª ADK with A2A Application Testing\n",
    "\n",
    "This notebook demonstrates how to test an ADK (Agent Development Kit) application that implements the Agent2Agent (A2A) protocol.\n",
    "It covers both local and remote testing, both with Agent Engine and Cloud Run."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install google-cloud-aiplatform a2a-sdk --upgrade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines if you're not using the virtual environment created by uv\n",
    "# import sys\n",
    "\n",
    "# sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ruff: noqa\n",
    "import asyncio\n",
    "import json\n",
    "import os\n",
    "import requests\n",
    "import uuid\n",
    "\n",
    "import vertexai\n",
    "from a2a.types import (\n",
    "    Message,\n",
    "    MessageSendParams,\n",
    "    Part,\n",
    "    Role,\n",
    "    SendStreamingMessageRequest,\n",
    "    TextPart,\n",
    ")\n",
    "from IPython.display import Markdown, display\n",
    "from google.adk.artifacts import InMemoryArtifactService\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "\n",
    "from app.agent_engine_app import AgentEngineApp\n",
    "from tests.helpers import (\n",
    "    build_get_request,\n",
    "    build_post_request,\n",
    "    poll_task_completion,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialize Vertex AI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Vertex AI client\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "client = vertexai.Client(\n",
    "    location=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you are using Agent Engine\n",
    "See more documentation at [Agent Engine Overview](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/overview)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set to None to auto-detect from ./deployment_metadata.json, or specify manually\n",
    "# \"projects/PROJECT_ID/locations/us-central1/reasoningEngines/ENGINE_ID\"\n",
    "REASONING_ENGINE_ID = None\n",
    "\n",
    "if REASONING_ENGINE_ID is None:\n",
    "    try:\n",
    "        with open(\"../deployment_metadata.json\") as f:\n",
    "            metadata = json.load(f)\n",
    "            REASONING_ENGINE_ID = metadata.get(\"remote_agent_engine_id\")\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        pass\n",
    "\n",
    "print(f\"Using REASONING_ENGINE_ID: {REASONING_ENGINE_ID}\")\n",
    "# Get the existing agent engine\n",
    "remote_agent_engine = client.agent_engines.get(name=REASONING_ENGINE_ID)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Agent Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_a2a_agent_card = await remote_agent_engine.handle_authenticated_agent_card()\n",
    "print(f\"Agent: {remote_a2a_agent_card.name}\")\n",
    "print(f\"URL: {remote_a2a_agent_card.url}\")\n",
    "print(f\"Skills: {[s.description for s in remote_a2a_agent_card.skills]}\")\n",
    "print(f\"Examples: {[s.examples for s in remote_a2a_agent_card.skills][0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Send the message using A2A protocol\n",
    "message_data = {\n",
    "    \"messageId\": f\"msg-{os.urandom(8).hex()}\",\n",
    "    \"role\": \"user\",\n",
    "    \"parts\": [{\"kind\": \"text\", \"text\": \"What is the weather in New York?\"}],\n",
    "}\n",
    "\n",
    "response = await remote_agent_engine.on_message_send(**message_data)\n",
    "\n",
    "# Extract task object from response\n",
    "task_object = None\n",
    "for chunk in response:\n",
    "    if isinstance(chunk, tuple) and chunk and hasattr(chunk[0], \"id\"):\n",
    "        task_object = chunk[0]\n",
    "        break\n",
    "\n",
    "# Get task_id\n",
    "if task_object:\n",
    "    task_id = task_object.id\n",
    "    print(f\"Task started: {task_id}\")\n",
    "else:\n",
    "    print(\"Could not retrieve the task object from the response.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poll for response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll for task completion\n",
    "max_attempts = 30\n",
    "for attempt in range(max_attempts):\n",
    "    result = await remote_agent_engine.on_get_task(id=task_id, historyLength=1)\n",
    "\n",
    "    task_state = result.status.state if hasattr(result, \"status\") else None\n",
    "    print(f\"Attempt {attempt + 1}: {task_state}\")\n",
    "\n",
    "    if task_state == \"completed\":\n",
    "        print(\"Task completed!\")\n",
    "        break\n",
    "    elif task_state == \"failed\":\n",
    "        print(f\"Task failed: {result}\")\n",
    "        break\n",
    "\n",
    "    await asyncio.sleep(1)\n",
    "\n",
    "# Extract and display artifacts\n",
    "if hasattr(result, \"artifacts\") and result.artifacts:\n",
    "    for artifact in result.artifacts:\n",
    "        if artifact.parts and hasattr(artifact.parts[0], \"root\"):\n",
    "            text = getattr(artifact.parts[0].root, \"text\", None)\n",
    "            if text:\n",
    "                display(Markdown(f\"**Answer**:\\n {text}\"))\n",
    "            else:\n",
    "                print(\"Could not extract text from artifact parts.\")\n",
    "        else:\n",
    "            print(\"Could not extract text from artifact parts.\")\n",
    "else:\n",
    "    print(\"No artifacts found in result\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "remote_agent_engine.register_feedback(\n",
    "    feedback={\n",
    "        \"score\": 5,\n",
    "        \"text\": \"Great response!\",\n",
    "        \"invocation_id\": \"test-invocation-123\",\n",
    "        \"user_id\": \"test\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing\n",
    "\n",
    "You can import directly the AgentEngineApp class within your environment. \n",
    "To run the agent locally, follow these steps:\n",
    "1. Make sure all required packages are installed in your environment\n",
    "2. The recommended approach is to use the same virtual environment created by the 'uv' tool\n",
    "3. You can set up this environment by running 'make install' from your agent's root directory\n",
    "4. Then select this kernel (.venv folder in your project) in your Jupyter notebook to ensure all dependencies are available"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up local Agent Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_agent_engine = await AgentEngineApp.create(\n",
    "    artifact_service_builder=lambda: InMemoryArtifactService(),\n",
    "    session_service_builder=lambda: InMemorySessionService(),\n",
    ")\n",
    "local_agent_engine.set_up()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Verify Custom Method is Registered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = local_agent_engine.register_operations()\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fetch Agent Card"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = build_get_request(None)\n",
    "response = await local_agent_engine.handle_authenticated_agent_card(\n",
    "    request=request, context=None\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Send Message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "message_data = {\n",
    "    \"message\": {\n",
    "        \"messageId\": f\"msg-{os.urandom(8).hex()}\",\n",
    "        \"content\": [{\"text\": \"What is the weather in New York?\"}],\n",
    "        \"role\": \"ROLE_USER\",\n",
    "    },\n",
    "}\n",
    "request = build_post_request(message_data)\n",
    "\n",
    "response = await local_agent_engine.on_message_send(request=request, context=None)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Poll for response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_id = response[\"task\"][\"id\"]\n",
    "print(f\"The Task ID is: {task_id}\")\n",
    "\n",
    "# Poll for completion using helper\n",
    "final_response = await poll_task_completion(local_agent_engine, task_id)\n",
    "\n",
    "# Extract and display artifacts\n",
    "for artifact in final_response[\"artifacts\"]:\n",
    "    if artifact[\"parts\"] and \"text\" in artifact[\"parts\"][0]:\n",
    "        display(Markdown(f\"**Answer**:\\n {artifact['parts'][0]['text']}\"))\n",
    "    else:\n",
    "        print(\"Could not extract text from artifact parts.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Register Feedback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "local_agent_engine.register_feedback(\n",
    "    feedback={\n",
    "        \"score\": 5,\n",
    "        \"text\": \"Great response!\",\n",
    "        \"invocation_id\": \"test-invocation-123\",\n",
    "        \"user_id\": \"test\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## If you are using Cloud Run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remote Testing\n",
    "\n",
    "For more information about authenticating HTTPS requests to Cloud Run services, see:\n",
    "[Cloud Run Authentication Documentation](https://cloud.google.com/run/docs/triggering/https-request)\n",
    "\n",
    "Remote testing involves using a deployed service URL instead of localhost.\n",
    "\n",
    "Authentication is handled using GCP identity tokens instead of local credentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_TOKEN = get_ipython().getoutput(\"gcloud auth print-identity-token -q\")[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVICE_URL = \"YOUR_SERVICE_URL_HERE\"  # Replace with your Cloud Run service URL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send a message using A2A protocol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A2A message request\n",
    "message = Message(\n",
    "    message_id=f\"msg-user-{uuid.uuid4()}\",\n",
    "    role=Role.user,\n",
    "    parts=[Part(root=TextPart(text=\"Hello! Weather in New York?\"))],\n",
    ")\n",
    "\n",
    "request = SendStreamingMessageRequest(\n",
    "    id=f\"req-{uuid.uuid4()}\",\n",
    "    params=MessageSendParams(message=message),\n",
    ")\n",
    "\n",
    "# Set up headers with authentication\n",
    "headers = {\"Content-Type\": \"application/json\", \"Authorization\": f\"Bearer {ID_TOKEN}\"}\n",
    "\n",
    "# Send the streaming request to the A2A endpoint\n",
    "response = requests.post(\n",
    "    f\"{SERVICE_URL}/a2a/app/\",\n",
    "    headers=headers,\n",
    "    json=request.model_dump(mode=\"json\", exclude_none=True),\n",
    "    stream=True,\n",
    "    timeout=60,\n",
    ")\n",
    "\n",
    "print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "# Parse streaming A2A responses\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line_str = line.decode(\"utf-8\")\n",
    "        if line_str.startswith(\"data: \"):\n",
    "            event_json = line_str[6:]\n",
    "            event = json.loads(event_json)\n",
    "            print(f\"Received event: {event}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Testing\n",
    "\n",
    "> You can run the application locally via the `make local-backend` command.\n",
    "\n",
    "Send a message to the local backend service using the A2A protocol and receive a streaming response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A2A message request\n",
    "message = Message(\n",
    "    message_id=f\"msg-user-{uuid.uuid4()}\",\n",
    "    role=Role.user,\n",
    "    parts=[Part(root=TextPart(text=\"Hello! Weather in New York?\"))],\n",
    ")\n",
    "\n",
    "request = SendStreamingMessageRequest(\n",
    "    id=f\"req-{uuid.uuid4()}\",\n",
    "    params=MessageSendParams(message=message),\n",
    ")\n",
    "\n",
    "# Set up headers\n",
    "headers = {\"Content-Type\": \"application/json\"}\n",
    "\n",
    "# Send the streaming request to the local A2A endpoint\n",
    "response = requests.post(\n",
    "    \"http://127.0.0.1:8000/a2a/app/\",\n",
    "    headers=headers,\n",
    "    json=request.model_dump(mode=\"json\", exclude_none=True),\n",
    "    stream=True,\n",
    "    timeout=60,\n",
    ")\n",
    "\n",
    "print(f\"Response status code: {response.status_code}\")\n",
    "\n",
    "# Parse streaming A2A responses\n",
    "for line in response.iter_lines():\n",
    "    if line:\n",
    "        line_str = line.decode(\"utf-8\")\n",
    "        if line_str.startswith(\"data: \"):\n",
    "            event_json = line_str[6:]\n",
    "            event = json.loads(event_json)\n",
    "            print(f\"Received event: {event}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "a2a-ae-starter-temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
