# Copyright 2025 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

steps:
{%- if cookiecutter.data_ingestion %}
  - name: "python:3.11-slim"
    id: deploy-data-ingestion-pipeline-staging
    entrypoint: bash
    args:
      - -c
      - |
        cd data_ingestion && pip install uv==0.6.12 --user && cd data_ingestion_pipeline && \
        uv sync --locked && uv run python submit_pipeline.py
    env:
      - "PIPELINE_ROOT=${_PIPELINE_GCS_ROOT}"
      - "REGION=${_REGION}"
{%- if cookiecutter.datastore_type == "vertex_ai_search" %}
      - "DATA_STORE_REGION=${_DATA_STORE_REGION}"
      - "DATA_STORE_ID=${_DATA_STORE_ID}"
{%- elif cookiecutter.datastore_type == "vertex_ai_vector_search" %}
      - "VECTOR_SEARCH_INDEX=${_VECTOR_SEARCH_INDEX}"
      - "VECTOR_SEARCH_INDEX_ENDPOINT=${_VECTOR_SEARCH_INDEX_ENDPOINT}"
      - "VECTOR_SEARCH_BUCKET=${_VECTOR_SEARCH_BUCKET}"
{%- endif %}
      - "PROJECT_ID=${_STAGING_PROJECT_ID}"
      - "SERVICE_ACCOUNT=${_PIPELINE_SA_EMAIL}"
      - "PIPELINE_NAME=${_PIPELINE_NAME}"
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'
{%- endif %}
{%- if cookiecutter.deployment_target == 'cloud_run' %}
  # Build and Push
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
        "--build-arg",
        "COMMIT_SHA=$COMMIT_SHA",
        ".",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
      ]

  # Deploy to Staging
  - name: "gcr.io/cloud-builders/gcloud"
    id: deploy-staging
    entrypoint: gcloud
    args:
      - "run"
      - "deploy"
      - "{{cookiecutter.project_name}}"
      - "--image"
      - "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME"
      - "--region"
      - "${_REGION}"
      - "--project"
      - "${_STAGING_PROJECT_ID}"

  # Fetch Staging Service URL
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-staging-url
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud run services describe {{cookiecutter.project_name}} \
        --region ${_REGION} --project ${_STAGING_PROJECT_ID} --format="value(status.url)") > staging_url.txt

  # Fetch ID Token
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-id-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-identity-token -q) > id_token.txt
{%- elif cookiecutter.deployment_target == 'gke' %}
  # Build and Push
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "build",
        "-t",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
        "--build-arg",
        "COMMIT_SHA=$COMMIT_SHA",
        ".",
      ]
  - name: "gcr.io/cloud-builders/docker"
    args:
      [
        "push",
        "$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME",
      ]

  # Get GKE credentials
  - name: "gcr.io/cloud-builders/gcloud"
    id: get-gke-credentials-staging
    entrypoint: gcloud
    args:
      - "container"
      - "clusters"
      - "get-credentials"
      - "{{cookiecutter.project_name}}-cluster-staging"
      - "--region"
      - "${_REGION}"
      - "--project"
      - "${_STAGING_PROJECT_ID}"

  # Deploy to Staging by setting the new image
  - name: "gcr.io/cloud-builders/gcloud"
    id: deploy-staging
    entrypoint: kubectl
    args:
      - "set"
      - "image"
      - "deployment/{{cookiecutter.project_name}}-deployment"
      - "{{cookiecutter.project_name}}=$_REGION-docker.pkg.dev/$PROJECT_ID/$_ARTIFACT_REGISTRY_REPO_NAME/$_CONTAINER_NAME"

  # Fetch Staging Service URL
  - name: "gcr.io/cloud-builders/gcloud"
    id: fetch-staging-url
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        # Wait for the Ingress to get an external IP
        for i in {1..30}; do
          IP=$(kubectl get ingress {{cookiecutter.project_name}}-ingress --namespace default --output jsonpath='{.status.loadBalancer.ingress[0].ip}');
          if [ -n "$IP" ]; then
            echo "http://$IP" > staging_url.txt;
            exit 0;
          fi;
          echo "Waiting for Ingress external IP... ($i/30)";
          sleep 10;
        done;
        echo "Failed to get external IP for the Ingress." >&2;
        exit 1
  # Fetch OIDC Token for IAP
  - name: gcr.io/cloud-builders/gcloud
    id: fetch-iap-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        # The audience is the IAP client ID
        export _IAP_CLIENT_ID=$(gcloud iap oauth-clients list --project=${_STAGING_PROJECT_ID} --filter="displayName={{cookiecutter.project_name}}-iap-client-staging" --format="value(name.split('/').pop())")
        echo $(gcloud auth print-identity-token --audiences=$_IAP_CLIENT_ID -q) > iap_token.txt
{%- elif cookiecutter.deployment_target == 'agent_engine' %}
  - name: "python:3.11-slim" 
    id: install-dependencies
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        pip install uv==0.6.12 --user && uv sync --locked
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'

  - name: "python:3.11-slim"
    id: deploy-staging
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        uv export --no-hashes --no-sources --no-header --no-dev --no-emit-project --no-annotate --locked > .requirements.txt
        uv run app/agent_engine_app.py \
          --project ${_STAGING_PROJECT_ID} \
          --location ${_REGION} \
          --set-env-vars="COMMIT_SHA=${COMMIT_SHA}{%- if cookiecutter.data_ingestion %}{%- if cookiecutter.datastore_type == "vertex_ai_search" %},DATA_STORE_ID=${_DATA_STORE_ID},DATA_STORE_REGION=${_DATA_STORE_REGION}{%- elif cookiecutter.datastore_type == "vertex_ai_vector_search" %},VECTOR_SEARCH_INDEX=${_VECTOR_SEARCH_INDEX},VECTOR_SEARCH_INDEX_ENDPOINT=${_VECTOR_SEARCH_INDEX_ENDPOINT},VECTOR_SEARCH_BUCKET=${_VECTOR_SEARCH_BUCKET}{%- endif %}{%- endif %}"
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'


  - name: gcr.io/cloud-builders/gcloud
    id: fetch-auth-token
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo $(gcloud auth print-access-token -q) > auth_token.txt
{%- endif %}

  # Load Testing
  - name: "python:3.11-slim"
    id: load_test
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
{%- if cookiecutter.deployment_target == 'cloud_run' %}
        export _ID_TOKEN=$(cat id_token.txt)
        export _STAGING_URL=$(cat staging_url.txt)
{%- elif cookiecutter.deployment_target == 'gke' %}
        export _ID_TOKEN=$(cat iap_token.txt)
        export _STAGING_URL=$(cat staging_url.txt)
{%- elif cookiecutter.deployment_target == 'agent_engine' %}
        export _AUTH_TOKEN=$(cat auth_token.txt)
{%- endif %}
        pip install locust==2.31.1 --user
        locust -f tests/load_test/load_test.py \
        --headless \
{%- if cookiecutter.deployment_target == 'cloud_run' or cookiecutter.deployment_target == 'gke' %}
        -H $_STAGING_URL \
        -t 30s -u 10 -r 0.5 \
{%- elif cookiecutter.deployment_target == 'agent_engine' %}
        -t 30s -u 2 -r 0.5 \
{%- endif %}
        --csv=tests/load_test/.results/results \
        --html=tests/load_test/.results/report.html
    env:
      - 'PATH=/usr/local/bin:/usr/bin:~/.local/bin'

  # Export Load Test Results to GCS
  - name: gcr.io/cloud-builders/gcloud
    id: export-results-to-gcs
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        export _TIMESTAMP=$(date +%Y%m%d-%H%M%S)
        gsutil -m cp -r tests/load_test/.results gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}
        echo "_________________________________________________________________________"
        echo "Load test results copied to gs://${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "HTTP link: https://console.cloud.google.com/storage/browser/${_BUCKET_NAME_LOAD_TEST_RESULTS}/results-$${_TIMESTAMP}"
        echo "_________________________________________________________________________"

  # Trigger Prod Deployment
  - name: gcr.io/cloud-builders/gcloud
    id: trigger-prod-deployment
    entrypoint: gcloud
    args:
      - "beta"
      - "builds"
      - "triggers"
      - "run"
      - "deploy-{{cookiecutter.project_name}}"
      - "--region"
      - "$LOCATION"
      - "--project"
      - "$PROJECT_ID"
      - "--sha"
      - $COMMIT_SHA

  - name: gcr.io/cloud-builders/gcloud
    id: echo-view-build-trigger-link
    entrypoint: /bin/bash
    args:
      - "-c"
      - |
        echo "_________________________________________________________________________"
        echo "Production deployment triggered. View progress and / or approve on the Cloud Build Console:"
        echo "https://console.cloud.google.com/cloud-build/builds;region=$LOCATION"
        echo "_________________________________________________________________________"

substitutions:
  _STAGING_PROJECT_ID: YOUR_STAGING_PROJECT_ID
  _REGION: us-central1

logsBucket: gs://${PROJECT_ID}-{{ cookiecutter.project_name | replace('_', '-') }}-logs-data/build-logs
options:
  substitutionOption: ALLOW_LOOSE
  defaultLogsBucketBehavior: REGIONAL_USER_OWNED_BUCKET
